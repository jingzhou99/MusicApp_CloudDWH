{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#  Cloud Data Warehouse _ Music Streaming Business "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Note:\n",
    "This ipynd file contain 5 parts\n",
    "\n",
    "    PART 1 _ Create IAM role and attach policy\n",
    "        1.1 Parse 'dwh_1.cfg' file\n",
    "        1.2 Create Resources & Clients\n",
    "        1.3 Create IAM role\n",
    "    Part 2 _ Create Redshift Cluster\n",
    "        2.1 Create & Validate Cluster\n",
    "        2.2 Set Security Group and CIDR\n",
    "    Part 3 _ ETL\n",
    "        3.1 Create Staging Tables & New Schema\n",
    "        3.2 ETL (Load,Transform,Insert)\n",
    "    Part 4 _ Data Analytics\n",
    "        4.1 How many users in total?\n",
    "        4.2 How many active users?\n",
    "        4.3 Top 10 songs\n",
    "        4.4 How many songs been played for each month?\n",
    "    Part 5 _ Vacum/Analyze/Delete Cluster/Delete Role\n",
    "\n",
    "Recommendation:\n",
    " - If you have AMAZON AWS account, and prefer a Iac approach, you can follow below steps, with only your AccessKey (KEY and SECRET).\n",
    " - If you already manually created role, policy, set security group and redshift clusters. you can jump to **PART 3** and start from there.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "import configparser\n",
    "from botocore.exceptions import ClientError\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# PART 1 _ Create IAM role and attach policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 1.1 Parse 'dwh_1.cfg' file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "\n",
    "# admin accesskey\n",
    "KEY = config.get('AWS','KEY')\n",
    "SECRET = config.get('AWS','SECRET')\n",
    "\n",
    "# configuration for creating redshift cluster\n",
    "DWH_CLUSTER_TYPE = config.get('DWH','DWH_CLUSTER_TYPE')\n",
    "DWH_NUM_NODES = config.get('DWH','DWH_NUM_NODES')\n",
    "DWH_NODE_TYPE = config.get('DWH','DWH_NODE_TYPE')\n",
    "\n",
    "DWH_CLUSTER_IDENTIFIER = config.get('DWH','DWH_CLUSTER_IDENTIFIER')\n",
    "DWH_DB = config.get('DWH','DWH_DB')\n",
    "DWH_DB_USER = config.get('DWH','DWH_DB_USER')\n",
    "DWH_DB_PASSWORD = config.get('DWH','DWH_DB_PASSWORD')\n",
    "DWH_PORT = config.get('DWH','DWH_PORT')\n",
    "\n",
    "# name of IAM role, which shall also have S3readonly policy\n",
    "DWH_IAM_ROLE_NAME = config.get('DWH','DWH_IAM_ROLE_NAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Param</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DWH_CLUSTER_TYPE</td>\n",
       "      <td>multi-node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DWH_NUM_NODES</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DWH_NODE_TYPE</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DWH_CLUSTER_IDENTIFIER</td>\n",
       "      <td>dwhCluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DWH_DB</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DWH_DB_USER</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DWH_DB_PASSWORD</td>\n",
       "      <td>Passw0rd123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DWH_PORT</td>\n",
       "      <td>5439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DWH_IAM_ROLE_NAME</td>\n",
       "      <td>dwhRole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Param        Value\n",
       "0        DWH_CLUSTER_TYPE   multi-node\n",
       "1           DWH_NUM_NODES            4\n",
       "2           DWH_NODE_TYPE    dc2.large\n",
       "3  DWH_CLUSTER_IDENTIFIER   dwhCluster\n",
       "4                  DWH_DB          dwh\n",
       "5             DWH_DB_USER      dwhuser\n",
       "6         DWH_DB_PASSWORD  Passw0rd123\n",
       "7                DWH_PORT         5439\n",
       "8       DWH_IAM_ROLE_NAME      dwhRole"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print .cfg content to check\n",
    "pd.DataFrame({\"Param\":\n",
    "                  [\"DWH_CLUSTER_TYPE\", \"DWH_NUM_NODES\", \"DWH_NODE_TYPE\", \"DWH_CLUSTER_IDENTIFIER\", \"DWH_DB\", \"DWH_DB_USER\", \"DWH_DB_PASSWORD\", \"DWH_PORT\", \"DWH_IAM_ROLE_NAME\"],\n",
    "              \"Value\":\n",
    "                  [DWH_CLUSTER_TYPE, DWH_NUM_NODES, DWH_NODE_TYPE, DWH_CLUSTER_IDENTIFIER, DWH_DB, DWH_DB_USER, DWH_DB_PASSWORD, DWH_PORT, DWH_IAM_ROLE_NAME]\n",
    "             })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 1.2 Create Resources & Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Resources and Clients Created.---\n"
     ]
    }
   ],
   "source": [
    "ec2 = boto3.resource('ec2',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                    )\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                   )\n",
    "\n",
    "iam = boto3.client('iam',\n",
    "                    aws_access_key_id=KEY,\n",
    "                    aws_secret_access_key=SECRET,\n",
    "                    region_name='us-west-2'\n",
    "                  )\n",
    "\n",
    "redshift = boto3.client('redshift',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                       )\n",
    "\n",
    "print('---Resources and Clients Created.---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 1.3 Create IAM role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new IAM Role...\n",
      "An error occurred (EntityAlreadyExists) when calling the CreateRole operation: Role with name dwhRole already exists.\n"
     ]
    }
   ],
   "source": [
    "# from botocore.exceptions import ClientError\n",
    "\n",
    "# Create IAM role\n",
    "try:\n",
    "    print(\"Creating a new IAM Role...\") \n",
    "    dwhRole1 = iam.create_role(\n",
    "        Path='/',\n",
    "        RoleName=DWH_IAM_ROLE_NAME,\n",
    "        Description = \"Allows Redshift clusters to call AWS services on your behalf.\",\n",
    "        AssumeRolePolicyDocument=json.dumps(\n",
    "            {'Statement': [{'Action': 'sts:AssumeRole',\n",
    "               'Effect': 'Allow',\n",
    "               'Principal': {'Service': 'redshift.amazonaws.com'}}],\n",
    "               'Version': '2012-10-17'})\n",
    "    )    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# print('IAM role created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get the IAM role ARN\n"
     ]
    }
   ],
   "source": [
    "# attaching policy AmazonS3ReadOnlyAccess\n",
    "\n",
    "iam.attach_role_policy(RoleName=DWH_IAM_ROLE_NAME,\n",
    "                       PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"\n",
    "                      )['ResponseMetadata']['HTTPStatusCode']\n",
    "\n",
    "print(\"Get the IAM role ARN\")\n",
    "roleArn = iam.get_role(RoleName=DWH_IAM_ROLE_NAME)['Role']['Arn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::695143239337:role/dwhRole\n"
     ]
    }
   ],
   "source": [
    "print(roleArn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part 2 _ Create Redshift Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 2.1 Create & Validate Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    response = redshift.create_cluster(        \n",
    "        #cluster_config\n",
    "        ClusterType=DWH_CLUSTER_TYPE,\n",
    "        NodeType=DWH_NODE_TYPE,\n",
    "        NumberOfNodes=int(DWH_NUM_NODES),\n",
    "\n",
    "        #Identifiers & Credentials\n",
    "        DBName=DWH_DB,\n",
    "        ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,\n",
    "        MasterUsername=DWH_DB_USER,\n",
    "        MasterUserPassword=DWH_DB_PASSWORD,\n",
    "        \n",
    "        #Roles (for s3 access)\n",
    "        IamRoles=[roleArn]  \n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>dwhcluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'dwhcluster.czwptbpzjzag.us-west-2.redshift.amazonaws.com', 'Port': 5439}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-e7f0c69f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Key  \\\n",
       "0  ClusterIdentifier   \n",
       "1  NodeType            \n",
       "2  ClusterStatus       \n",
       "3  MasterUsername      \n",
       "4  DBName              \n",
       "5  Endpoint            \n",
       "6  VpcId               \n",
       "7  NumberOfNodes       \n",
       "\n",
       "                                                                                   Value  \n",
       "0  dwhcluster                                                                             \n",
       "1  dc2.large                                                                              \n",
       "2  available                                                                              \n",
       "3  dwhuser                                                                                \n",
       "4  dwh                                                                                    \n",
       "5  {'Address': 'dwhcluster.czwptbpzjzag.us-west-2.redshift.amazonaws.com', 'Port': 5439}  \n",
       "6  vpc-e7f0c69f                                                                           \n",
       "7  4                                                                                      "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run below scripts to check status of cluster just created.\n",
    "\n",
    "def prettyRedshiftProps(props):\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    keysToShow = [\"ClusterIdentifier\", \"NodeType\", \"ClusterStatus\", \"MasterUsername\", \"DBName\", \"Endpoint\", \"NumberOfNodes\", 'VpcId']\n",
    "    x = [(k, v) for k,v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data=x, columns=[\"Key\", \"Value\"])\n",
    "\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<span style=\"color:red\">WARNING: Run below scripts ONLY after you check the status of the cluster is \"AVAILABLE\"</span>     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWH_ENDPOINT ::  dwhcluster.czwptbpzjzag.us-west-2.redshift.amazonaws.com\n",
      "DWH_ROLE_ARN ::  arn:aws:iam::695143239337:role/dwhRole\n"
     ]
    }
   ],
   "source": [
    "# DWH_ENDPOINT will be used to construct the CONN_String. to connect to the cluster\n",
    "# DWH_ROLE_ARN  will be the credentials for Copy Command: copy data from S3 bucket\n",
    "\n",
    "DWH_ENDPOINT = myClusterProps['Endpoint']['Address']\n",
    "DWH_ROLE_ARN = myClusterProps['IamRoles'][0]['IamRoleArn']\n",
    "print(\"DWH_ENDPOINT :: \", DWH_ENDPOINT)\n",
    "print(\"DWH_ROLE_ARN :: \", DWH_ROLE_ARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "COPY DWH_ENDPOINT & DWH_ROLE_ARN  to .cfg file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 2.2 Set Security Group and CIDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2.SecurityGroup(id='sg-ab8acd9b')\n",
      "An error occurred (InvalidPermission.Duplicate) when calling the AuthorizeSecurityGroupIngress operation: the specified rule \"peer: 0.0.0.0/0, TCP, from port: 5439, to port: 5439, ALLOW\" already exists\n"
     ]
    }
   ],
   "source": [
    "# Here use the default security group\n",
    "# set CIDR to '0.0.0.0/0', not limit to a subnet\n",
    "\n",
    "try:\n",
    "    vpc = ec2.Vpc(id=myClusterProps['VpcId'])\n",
    "    defaultSg = list(vpc.security_groups.all())[0]\n",
    "    print(defaultSg)\n",
    "    defaultSg.authorize_ingress(\n",
    "        GroupName=defaultSg.group_name,\n",
    "        CidrIp='0.0.0.0/0',\n",
    "        IpProtocol='TCP',\n",
    "        FromPort=int(DWH_PORT),\n",
    "        ToPort=int(DWH_PORT)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "# VPC security group might already exist. That's fine to see error in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part 3 _ ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Run \"Create_table.py\" \n",
    "This will create: \n",
    " - a. Two staging table for copying source data from S3; \n",
    " - b. New schema, 5 tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# if you manually create cluster and role, uncomment below rows and paste endpoint and roleARN: \n",
    "# DWH_ENDPOINT = \n",
    "# DWH_ROLE_ARN = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 3.1 Create Staging Tables & New Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop all tables if exists\n",
      "executing DROP TABLE IF EXISTS \"staging_events\";\n",
      "executing DROP TABLE IF EXISTS staging_songs;\n",
      "executing DROP TABLE IF EXISTS \"songplays\";\n",
      "executing DROP TABLE IF EXISTS \"users\";\n",
      "executing DROP TABLE IF EXISTS \"songs\";\n",
      "executing DROP TABLE IF EXISTS \"artists\";\n",
      "executing DROP TABLE IF EXISTS \"time\";\n",
      "start creating new schema\n",
      "executing \n",
      "CREATE TABLE \"staging_events\" (\n",
      "    \"artist\" VARCHAR,\n",
      "    \"auth\" VARCHAR,\n",
      "    \"firstName\" VARCHAR,\n",
      "    \"gender\" VARCHAR,\n",
      "    \"itemInSession\" INT,\n",
      "    \"lastName\" VARCHAR,\n",
      "    \"length\" NUMERIC(9,5),\n",
      "    \"level\" VARCHAR,\n",
      "    \"location\" VARCHAR,\n",
      "    \"method\" VARCHAR,\n",
      "    \"page\" VARCHAR,\n",
      "    \"registration\" BIGINT,\n",
      "    \"sessionId\" INT,\n",
      "    \"song\" VARCHAR,\n",
      "    \"status\" INT,\n",
      "    \"ts\" BIGINT,\n",
      "    \"userAgent\" TEXT,\n",
      "    \"userId\" INT\n",
      "    );\n",
      "\n",
      "executing \n",
      "CREATE TABLE \"staging_songs\" (\n",
      "    \"num_songs\" INT, \n",
      "    \"artist_id\" VARCHAR, \n",
      "    \"artist_latitude\" numeric(8,5), \n",
      "    \"artist_longitude\" numeric(8,5),\n",
      "    \"artist_location\" VARCHAR, \n",
      "    \"artist_name\" VARCHAR,\n",
      "    \"song_id\" VARCHAR, \n",
      "    \"title\" VARCHAR, \n",
      "    \"duration\" NUMERIC(9,5), \n",
      "    \"year\" INT\n",
      "    );\n",
      "\n",
      "executing \n",
      "CREATE TABLE \"artists\" (\n",
      "    \"artist_id\" varchar PRIMARY KEY, \n",
      "    \"name\" varchar NOT NULL, \n",
      "    \"location\" varchar, \n",
      "    \"latitude\" numeric(8,5), \n",
      "    \"longitude\" numeric(8,5)\n",
      ");\n",
      "\n",
      "executing \n",
      "CREATE TABLE \"songs\" (\n",
      "    \"song_id\" varchar PRIMARY KEY, \n",
      "    \"title\" varchar NOT NULL, \n",
      "    \"artist_id\" varchar, \n",
      "    \"year\" int, \n",
      "    \"duration\" numeric(9,5),\n",
      "    FOREIGN KEY (\"artist_id\") REFERENCES \"artists\"\n",
      ") DISTKEY(song_id);\n",
      "\n",
      "executing \n",
      "CREATE TABLE \"users\" (\n",
      "    \"user_id\" int PRIMARY KEY, \n",
      "    \"first_name\" varchar(20) NOT NULL, \n",
      "    \"last_name\" varchar(20) NOT NULL, \n",
      "    \"gender\" varchar(5), \n",
      "    \"level\" varchar\n",
      ");\n",
      "\n",
      "executing \n",
      "CREATE TABLE \"time\" (\n",
      "    \"start_time\" TIMESTAMPTZ PRIMARY KEY, \n",
      "    \"hour\" int2, \n",
      "    \"day\" int2, \n",
      "    \"week\" int2, \n",
      "    \"month\" int2, \n",
      "    \"year\" int2, \n",
      "    \"weekday\" int2\n",
      ");\n",
      "\n",
      "executing \n",
      "CREATE TABLE \"songplays\" (\n",
      "    \"songplay_id\" INT IDENTITY(0,1) PRIMARY KEY, \n",
      "    \"start_time\" TIMESTAMPTZ NOT NULL, \n",
      "    \"user_id\" int NOT NULL, \n",
      "    \"level\" varchar, \n",
      "    \"song_id\" varchar, \n",
      "    \"artist_id\" varchar, \n",
      "    \"session_id\" int NOT NULL, \n",
      "    \"location\" varchar, \n",
      "    \"user_agent\" varchar,\n",
      "    FOREIGN KEY (\"user_id\") REFERENCES \"users\",\n",
      "    FOREIGN KEY (\"song_id\") REFERENCES \"songs\",\n",
      "    FOREIGN KEY (\"start_time\") REFERENCES \"time\"\n",
      ") DISTKEY(song_id);\n",
      "\n",
      "All tables been created.\n"
     ]
    }
   ],
   "source": [
    "%run -i create_tables.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### CHECK: whether table created or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://dwhuser:Passw0rd123@dwhcluster.czwptbpzjzag.us-west-2.redshift.amazonaws.com:5439/dwh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Connected: dwhuser@dwh'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext sql\n",
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".format(DWH_DB_USER, DWH_DB_PASSWORD, DWH_ENDPOINT, DWH_PORT,DWH_DB)\n",
    "print(conn_string)\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.czwptbpzjzag.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "7 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>schemaname</th>\n",
       "        <th>tablename</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>public</td>\n",
       "        <td>artists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>public</td>\n",
       "        <td>songplays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>public</td>\n",
       "        <td>songs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>public</td>\n",
       "        <td>staging_events</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>public</td>\n",
       "        <td>staging_songs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>public</td>\n",
       "        <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>public</td>\n",
       "        <td>users</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('public', 'artists'),\n",
       " ('public', 'songplays'),\n",
       " ('public', 'songs'),\n",
       " ('public', 'staging_events'),\n",
       " ('public', 'staging_songs'),\n",
       " ('public', 'time'),\n",
       " ('public', 'users')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT DISTINCT schemaname, tablename FROM \"pg_table_def\" WHERE schemaname='public';\n",
    "# it should show 7 table names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.czwptbpzjzag.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "9 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>schemaname</th>\n",
       "        <th>tablename</th>\n",
       "        <th>column</th>\n",
       "        <th>type</th>\n",
       "        <th>encoding</th>\n",
       "        <th>distkey</th>\n",
       "        <th>sortkey</th>\n",
       "        <th>notnull</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>public</td>\n",
       "        <td>songplays</td>\n",
       "        <td>songplay_id</td>\n",
       "        <td>integer</td>\n",
       "        <td>az64</td>\n",
       "        <td>False</td>\n",
       "        <td>0</td>\n",
       "        <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>public</td>\n",
       "        <td>songplays</td>\n",
       "        <td>start_time</td>\n",
       "        <td>timestamp with time zone</td>\n",
       "        <td>az64</td>\n",
       "        <td>False</td>\n",
       "        <td>0</td>\n",
       "        <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>public</td>\n",
       "        <td>songplays</td>\n",
       "        <td>user_id</td>\n",
       "        <td>integer</td>\n",
       "        <td>az64</td>\n",
       "        <td>False</td>\n",
       "        <td>0</td>\n",
       "        <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>public</td>\n",
       "        <td>songplays</td>\n",
       "        <td>level</td>\n",
       "        <td>character varying(256)</td>\n",
       "        <td>lzo</td>\n",
       "        <td>False</td>\n",
       "        <td>0</td>\n",
       "        <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>public</td>\n",
       "        <td>songplays</td>\n",
       "        <td>song_id</td>\n",
       "        <td>character varying(256)</td>\n",
       "        <td>lzo</td>\n",
       "        <td>True</td>\n",
       "        <td>0</td>\n",
       "        <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>public</td>\n",
       "        <td>songplays</td>\n",
       "        <td>artist_id</td>\n",
       "        <td>character varying(256)</td>\n",
       "        <td>lzo</td>\n",
       "        <td>False</td>\n",
       "        <td>0</td>\n",
       "        <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>public</td>\n",
       "        <td>songplays</td>\n",
       "        <td>session_id</td>\n",
       "        <td>integer</td>\n",
       "        <td>az64</td>\n",
       "        <td>False</td>\n",
       "        <td>0</td>\n",
       "        <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>public</td>\n",
       "        <td>songplays</td>\n",
       "        <td>location</td>\n",
       "        <td>character varying(256)</td>\n",
       "        <td>lzo</td>\n",
       "        <td>False</td>\n",
       "        <td>0</td>\n",
       "        <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>public</td>\n",
       "        <td>songplays</td>\n",
       "        <td>user_agent</td>\n",
       "        <td>character varying(256)</td>\n",
       "        <td>lzo</td>\n",
       "        <td>False</td>\n",
       "        <td>0</td>\n",
       "        <td>False</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('public', 'songplays', 'songplay_id', 'integer', 'az64', False, 0, True),\n",
       " ('public', 'songplays', 'start_time', 'timestamp with time zone', 'az64', False, 0, True),\n",
       " ('public', 'songplays', 'user_id', 'integer', 'az64', False, 0, True),\n",
       " ('public', 'songplays', 'level', 'character varying(256)', 'lzo', False, 0, False),\n",
       " ('public', 'songplays', 'song_id', 'character varying(256)', 'lzo', True, 0, False),\n",
       " ('public', 'songplays', 'artist_id', 'character varying(256)', 'lzo', False, 0, False),\n",
       " ('public', 'songplays', 'session_id', 'integer', 'az64', False, 0, True),\n",
       " ('public', 'songplays', 'location', 'character varying(256)', 'lzo', False, 0, False),\n",
       " ('public', 'songplays', 'user_agent', 'character varying(256)', 'lzo', False, 0, False)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM \"pg_table_def\" WHERE tablename='songplays';\n",
    "# check table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 3.2 ETL (Load,Transform,Insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading staging tables...\n",
      "executing \n",
      "    copy staging_events from 's3://udacity-dend/log_data'\n",
      "    credentials 'aws_iam_role=arn:aws:iam::695143239337:role/dwhRole'\n",
      "    json 's3://udacity-dend/log_json_path.json';\n",
      " this process might takes several minutes...be patient.\n",
      "executing \n",
      "    copy staging_songs from 's3://udacity-dend/song_data'\n",
      "    credentials 'aws_iam_role=arn:aws:iam::695143239337:role/dwhRole'\n",
      "    json 'auto';\n",
      " this process might takes several minutes...be patient.\n",
      "All staging tables loaded\n",
      "Start inserting job...\n",
      "executing \n",
      "BEGIN transaction;\n",
      "    DROP TABLE IF EXISTS temp_artists;\n",
      "    \n",
      "    -- only copy the distinct value from \"staging_songs\" to \"temp_artists\"\n",
      "    CREATE TABLE temp_artists AS\n",
      "    SELECT\n",
      "        artist_id,\n",
      "        artist_name,\n",
      "        artist_location,\n",
      "        artist_latitude,\n",
      "        artist_longitude\n",
      "    FROM\n",
      "        (SELECT\n",
      "            ROW_NUMBER() OVER (PARTITION BY artist_id order by artist_id) AS id_rank,\n",
      "            artist_id,\n",
      "            artist_name,\n",
      "            artist_location,\n",
      "            artist_latitude,\n",
      "            artist_longitude\n",
      "        FROM\n",
      "            staging_songs\n",
      "        ) r\n",
      "    WHERE r.id_rank = 1;\n",
      "\n",
      "    -- compare, and remove duplicate value in target table \"\"\n",
      "    DELETE FROM artists\n",
      "    USING temp_artists\n",
      "    WHERE temp_artists.artist_id = artists.artist_id;\n",
      "\n",
      "    INSERT INTO artists (\n",
      "        artist_id, \n",
      "        name, \n",
      "        location, \n",
      "        latitude, \n",
      "        longitude\n",
      "        )\n",
      "    SELECT\n",
      "        artist_id,\n",
      "        artist_name,\n",
      "        artist_location,\n",
      "        artist_latitude,\n",
      "        artist_longitude\n",
      "    FROM\n",
      "        temp_artists;\n",
      "        \n",
      "    DROP TABLE temp_artists;\n",
      "\n",
      "END transaction;\n",
      " this process might takes several minutes...be patient.\n",
      "executing \n",
      "INSERT INTO songs (\n",
      "    song_id,\n",
      "    title, \n",
      "    artist_id, \n",
      "    year, \n",
      "    duration\n",
      "    ) \n",
      "SELECT\n",
      "    s.song_id,\n",
      "    s.title,\n",
      "    s.artist_id,\n",
      "    s.year,\n",
      "    s.duration\n",
      "FROM\n",
      "    staging_songs s\n",
      ";\n",
      " this process might takes several minutes...be patient.\n",
      "executing \n",
      "BEGIN transaction;\n",
      "    DROP TABLE IF EXISTS temp_users;\n",
      "\n",
      "    --only copy distinct value from staging_events \n",
      "    CREATE TABLE temp_users AS\n",
      "    SELECT\n",
      "        userId,\n",
      "        firstName,\n",
      "        lastName,\n",
      "        gender,\n",
      "        level\n",
      "    FROM\n",
      "        (SELECT\n",
      "            ROW_NUMBER() OVER (PARTITION BY userId order by ts DESC) AS id_rank,\n",
      "            userId,\n",
      "            firstName,\n",
      "            lastName,\n",
      "            gender,\n",
      "            level\n",
      "        FROM\n",
      "            staging_events\n",
      "        WHERE\n",
      "            userId IS NOT NULL\n",
      "        ) u\n",
      "    WHERE u.id_rank = 1;\n",
      "    \n",
      "    -- remove duplicates in target table, before dump\n",
      "    DELETE FROM \"users\"\n",
      "    USING temp_users\n",
      "    WHERE users.user_id = temp_users.userId;\n",
      "\n",
      "    INSERT INTO \"users\" (\n",
      "        user_id, \n",
      "        first_name, \n",
      "        last_name, \n",
      "        gender, \n",
      "        level )\n",
      "    SELECT\n",
      "        userId,\n",
      "        firstName,\n",
      "        lastName,\n",
      "        gender,\n",
      "        level\n",
      "    FROM\n",
      "        temp_users;\n",
      "\n",
      "    DROP TABLE temp_users;    \n",
      "END transaction;\n",
      " this process might takes several minutes...be patient.\n",
      "executing \n",
      "BEGIN transaction;\n",
      "    --create temp table, put all the time data into it\n",
      "    CREATE TEMP TABLE IF NOT EXISTS temp_table (like time);\n",
      "    TRUNCATE temp_table;\n",
      "\n",
      "    INSERT INTO temp_table\n",
      "    SELECT * FROM time;\n",
      "\n",
      "    INSERT INTO temp_table\n",
      "    SELECT\n",
      "        (timestamp 'epoch' + (e.ts/1000) * interval '1 second') AS \"start_time\", --13 digits int, which means ms precision, so devide by 1000\n",
      "        date_part('hour',(timestamp 'epoch' + (e.ts/1000) * interval '1 second')) AS \"hour\",\n",
      "        date_part('day',(timestamp 'epoch' + (e.ts/1000) * interval '1 second')) AS \"day\",\n",
      "        date_part('week',(timestamp 'epoch' + (e.ts/1000) * interval '1 second')) AS \"week\",\n",
      "        date_part('month',(timestamp 'epoch' + (e.ts/1000) * interval '1 second')) AS \"month\",\n",
      "        date_part('year',(timestamp 'epoch' + (e.ts/1000) * interval '1 second')) AS \"year\",\n",
      "        date_part('dow',(timestamp 'epoch' + (e.ts/1000) * interval '1 second')) AS \"weekday\"\n",
      "    FROM    \n",
      "        staging_events e\n",
      "    WHERE\n",
      "        e.\"page\"='NextSong';\n",
      "    \n",
      "    --empty time table, and write back only distinct time data\n",
      "    TRUNCATE time;\n",
      "\n",
      "    INSERT INTO time\n",
      "    SELECT\n",
      "        start_time, \n",
      "        hour, \n",
      "        day, \n",
      "        week, \n",
      "        month, \n",
      "        year, \n",
      "        weekday\n",
      "    FROM\n",
      "        (SELECT\n",
      "             ROW_NUMBER()OVER(PARTITION BY start_time ORDER BY start_time) AS rank_num,\n",
      "             temp_table.*     \n",
      "         FROM \n",
      "             temp_table\n",
      "        ) AS tt\n",
      "    WHERE tt.rank_num = 1;\n",
      "    \n",
      "    DROP TABLE temp_table;\n",
      "\n",
      "END transaction;\n",
      " this process might takes several minutes...be patient.\n",
      "executing \n",
      "INSERT INTO songplays (\n",
      "    start_time, \n",
      "    user_id, \n",
      "    level, \n",
      "    song_id, \n",
      "    artist_id, \n",
      "    session_id, \n",
      "    location, \n",
      "    user_agent\n",
      "    ) \n",
      "SELECT\n",
      "    (timestamp 'epoch' + (e.ts/1000) * interval '1 second') AS start_time,\n",
      "    e.userId as user_id,\n",
      "    e.level AS level,\n",
      "    sa.song_id AS song_id,\n",
      "    sa.artist_id AS artist_id,\n",
      "    e.sessionId AS session_id,\n",
      "    e.location AS location,\n",
      "    e.userAgent AS user_agent\n",
      "FROM \n",
      "    staging_events AS e\n",
      "JOIN \n",
      "    (SELECT\n",
      "        s.song_id,\n",
      "        s.title,\n",
      "        s.duration,\n",
      "        a.artist_id,\n",
      "        a.name\n",
      "    FROM songs AS s\n",
      "    JOIN artists AS a ON s.artist_id = a.artist_id\n",
      "    ) AS sa\n",
      "    ON (e.song=sa.title AND e.length=sa.duration AND e.artist=sa.name)\n",
      "WHERE\n",
      "    e.\"page\"='NextSong';\n",
      " this process might takes several minutes...be patient.\n",
      "All data inserted.\n",
      "ETL job done.\n"
     ]
    }
   ],
   "source": [
    "%run etl.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### CHECK: how many data been inserted into each table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.czwptbpzjzag.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "7 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>etl job result</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>97 rows inserted into users</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>14896 rows inserted into staging_songs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>9553 rows inserted into artists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>6813 rows inserted into time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>301 rows inserted into songplays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>14896 rows inserted into songs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>8056 rows inserted into staging_events</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('97 rows inserted into users',),\n",
       " ('14896 rows inserted into staging_songs',),\n",
       " ('9553 rows inserted into artists',),\n",
       " ('6813 rows inserted into time',),\n",
       " ('301 rows inserted into songplays',),\n",
       " ('14896 rows inserted into songs',),\n",
       " ('8056 rows inserted into staging_events',)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "SELECT CONCAT((SELECT count(*) FROM staging_events),' rows inserted into staging_events') AS \"ETL job result\"\n",
    "UNION\n",
    "SELECT CONCAT((SELECT count(*) FROM staging_songs),' rows inserted into staging_songs')\n",
    "UNION\n",
    "SELECT CONCAT((SELECT count(*) FROM artists),' rows inserted into artists')\n",
    "UNION\n",
    "SELECT CONCAT((SELECT count(*) FROM songs),' rows inserted into songs')\n",
    "UNION\n",
    "SELECT CONCAT((SELECT count(*) FROM users),' rows inserted into users')\n",
    "UNION\n",
    "SELECT CONCAT((SELECT count(*) FROM time),' rows inserted into time')\n",
    "UNION\n",
    "SELECT CONCAT((SELECT count(*) FROM songplays),' rows inserted into songplays')\n",
    "; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.czwptbpzjzag.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>songplay_id</th>\n",
       "        <th>start_time</th>\n",
       "        <th>user_id</th>\n",
       "        <th>level</th>\n",
       "        <th>song_id</th>\n",
       "        <th>artist_id</th>\n",
       "        <th>session_id</th>\n",
       "        <th>location</th>\n",
       "        <th>user_agent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>76</td>\n",
       "        <td>2018-11-20 07:01:13+00:00</td>\n",
       "        <td>15</td>\n",
       "        <td>paid</td>\n",
       "        <td>SOSDYAS12AB0180457</td>\n",
       "        <td>ARA3I0J1187FB57869</td>\n",
       "        <td>716</td>\n",
       "        <td>Chicago-Naperville-Elgin, IL-IN-WI</td>\n",
       "        <td>&quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/36.0.1985.125 Chrome/36.0.1985.125 Safari/537.36&quot;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>108</td>\n",
       "        <td>2018-11-29 11:03:31+00:00</td>\n",
       "        <td>78</td>\n",
       "        <td>free</td>\n",
       "        <td>SOROSRY12A6D4F7B64</td>\n",
       "        <td>AR0WBBL1187FB4677D</td>\n",
       "        <td>931</td>\n",
       "        <td>Indianapolis-Carmel-Anderson, IN</td>\n",
       "        <td>Mozilla/5.0 (Windows NT 6.1; rv:31.0) Gecko/20100101 Firefox/31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>126</td>\n",
       "        <td>2018-11-21 04:20:28+00:00</td>\n",
       "        <td>97</td>\n",
       "        <td>paid</td>\n",
       "        <td>SOMEFTJ12A6D4F8CAC</td>\n",
       "        <td>AR7S2271187FB38B1F</td>\n",
       "        <td>797</td>\n",
       "        <td>Lansing-East Lansing, MI</td>\n",
       "        <td>&quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.94 Safari/537.36&quot;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>134</td>\n",
       "        <td>2018-11-29 18:05:39+00:00</td>\n",
       "        <td>49</td>\n",
       "        <td>paid</td>\n",
       "        <td>SOMEFTJ12A6D4F8CAC</td>\n",
       "        <td>AR7S2271187FB38B1F</td>\n",
       "        <td>1041</td>\n",
       "        <td>San Francisco-Oakland-Hayward, CA</td>\n",
       "        <td>Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20100101 Firefox/31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>142</td>\n",
       "        <td>2018-11-26 00:52:05+00:00</td>\n",
       "        <td>33</td>\n",
       "        <td>free</td>\n",
       "        <td>SONQEAO12A6D4F8CB3</td>\n",
       "        <td>AR7S2271187FB38B1F</td>\n",
       "        <td>827</td>\n",
       "        <td>Eugene, OR</td>\n",
       "        <td>&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36&quot;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>182</td>\n",
       "        <td>2018-11-07 05:32:06+00:00</td>\n",
       "        <td>50</td>\n",
       "        <td>free</td>\n",
       "        <td>SOXQUPO12A6D4FC2B6</td>\n",
       "        <td>AR79C1C1187FB4C482</td>\n",
       "        <td>313</td>\n",
       "        <td>New Haven-Milford, CT</td>\n",
       "        <td>&quot;Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36&quot;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>294</td>\n",
       "        <td>2018-11-16 16:27:21+00:00</td>\n",
       "        <td>90</td>\n",
       "        <td>free</td>\n",
       "        <td>SOMUJKC12AB01865AD</td>\n",
       "        <td>AR9RYZP1187FB36C6A</td>\n",
       "        <td>148</td>\n",
       "        <td>Pensacola-Ferry Pass-Brent, FL</td>\n",
       "        <td>Mozilla/5.0 (X11; Linux x86_64; rv:31.0) Gecko/20100101 Firefox/31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>302</td>\n",
       "        <td>2018-11-13 17:28:33+00:00</td>\n",
       "        <td>97</td>\n",
       "        <td>paid</td>\n",
       "        <td>SOIBHYW12AB0188F49</td>\n",
       "        <td>ARWNARC122BCFCAFEB</td>\n",
       "        <td>537</td>\n",
       "        <td>Lansing-East Lansing, MI</td>\n",
       "        <td>&quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.94 Safari/537.36&quot;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>310</td>\n",
       "        <td>2018-11-21 21:56:47+00:00</td>\n",
       "        <td>15</td>\n",
       "        <td>paid</td>\n",
       "        <td>SOZCTXZ12AB0182364</td>\n",
       "        <td>AR5KOSW1187FB35FF4</td>\n",
       "        <td>818</td>\n",
       "        <td>Chicago-Naperville-Elgin, IL-IN-WI</td>\n",
       "        <td>&quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/36.0.1985.125 Chrome/36.0.1985.125 Safari/537.36&quot;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>318</td>\n",
       "        <td>2018-11-27 12:19:30+00:00</td>\n",
       "        <td>24</td>\n",
       "        <td>paid</td>\n",
       "        <td>SOKXJKN12A6D4F86D5</td>\n",
       "        <td>ARVRAUT1187FB39AFB</td>\n",
       "        <td>879</td>\n",
       "        <td>Lake Havasu City-Kingman, AZ</td>\n",
       "        <td>&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36&quot;</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(76, datetime.datetime(2018, 11, 20, 7, 1, 13, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 15, 'paid', 'SOSDYAS12AB0180457', 'ARA3I0J1187FB57869', 716, 'Chicago-Naperville-Elgin, IL-IN-WI', '\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/36.0.1985.125 Chrome/36.0.1985.125 Safari/537.36\"'),\n",
       " (108, datetime.datetime(2018, 11, 29, 11, 3, 31, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 78, 'free', 'SOROSRY12A6D4F7B64', 'AR0WBBL1187FB4677D', 931, 'Indianapolis-Carmel-Anderson, IN', 'Mozilla/5.0 (Windows NT 6.1; rv:31.0) Gecko/20100101 Firefox/31.0'),\n",
       " (126, datetime.datetime(2018, 11, 21, 4, 20, 28, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 97, 'paid', 'SOMEFTJ12A6D4F8CAC', 'AR7S2271187FB38B1F', 797, 'Lansing-East Lansing, MI', '\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.94 Safari/537.36\"'),\n",
       " (134, datetime.datetime(2018, 11, 29, 18, 5, 39, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 49, 'paid', 'SOMEFTJ12A6D4F8CAC', 'AR7S2271187FB38B1F', 1041, 'San Francisco-Oakland-Hayward, CA', 'Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20100101 Firefox/31.0'),\n",
       " (142, datetime.datetime(2018, 11, 26, 0, 52, 5, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 33, 'free', 'SONQEAO12A6D4F8CB3', 'AR7S2271187FB38B1F', 827, 'Eugene, OR', '\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36\"'),\n",
       " (182, datetime.datetime(2018, 11, 7, 5, 32, 6, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 50, 'free', 'SOXQUPO12A6D4FC2B6', 'AR79C1C1187FB4C482', 313, 'New Haven-Milford, CT', '\"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"'),\n",
       " (294, datetime.datetime(2018, 11, 16, 16, 27, 21, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 90, 'free', 'SOMUJKC12AB01865AD', 'AR9RYZP1187FB36C6A', 148, 'Pensacola-Ferry Pass-Brent, FL', 'Mozilla/5.0 (X11; Linux x86_64; rv:31.0) Gecko/20100101 Firefox/31.0'),\n",
       " (302, datetime.datetime(2018, 11, 13, 17, 28, 33, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 97, 'paid', 'SOIBHYW12AB0188F49', 'ARWNARC122BCFCAFEB', 537, 'Lansing-East Lansing, MI', '\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.94 Safari/537.36\"'),\n",
       " (310, datetime.datetime(2018, 11, 21, 21, 56, 47, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 15, 'paid', 'SOZCTXZ12AB0182364', 'AR5KOSW1187FB35FF4', 818, 'Chicago-Naperville-Elgin, IL-IN-WI', '\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/36.0.1985.125 Chrome/36.0.1985.125 Safari/537.36\"'),\n",
       " (318, datetime.datetime(2018, 11, 27, 12, 19, 30, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=0, name=None)), 24, 'paid', 'SOKXJKN12A6D4F86D5', 'ARVRAUT1187FB39AFB', 879, 'Lake Havasu City-Kingman, AZ', '\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36\"')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM songplays where song_id IS NOT NULL LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Part 4 _ Data Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4.1 How many users in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.czwptbpzjzag.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>total_users_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>97</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(97,)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT count(*) AS Total_Users_Count FROM \"users\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4.2 How many active users? \n",
    "(login at least once this year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.czwptbpzjzag.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>total_activeusers_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>53</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(53,)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT count(DISTINCT \"user_id\") AS Total_ActiveUsers_Count \n",
    "FROM \"songplays\" s\n",
    "JOIN \"time\" t ON s.\"start_time\" = t.\"start_time\"\n",
    "WHERE \"year\" IN (select MAX(\"year\") FROM \"time\") AND \"user_id\" IS NOT NULL;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4.3 Top 10 songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.czwptbpzjzag.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>no.</th>\n",
       "        <th>title</th>\n",
       "        <th>play_times</th>\n",
       "        <th>artist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1</td>\n",
       "        <td>You&#x27;re The One</td>\n",
       "        <td>37</td>\n",
       "        <td>Dwight Yoakam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2</td>\n",
       "        <td>Catch You Baby (Steve Pitron &amp; Max Sanna Radio Edit)</td>\n",
       "        <td>9</td>\n",
       "        <td>Lonnie Gordon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>3</td>\n",
       "        <td>I CAN&#x27;T GET STARTED</td>\n",
       "        <td>9</td>\n",
       "        <td>Ron Carter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>4</td>\n",
       "        <td>Nothin&#x27; On You [feat. Bruno Mars] (Album Version)</td>\n",
       "        <td>8</td>\n",
       "        <td>B.o.B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>5</td>\n",
       "        <td>Hey Daddy (Daddy&#x27;s Home)</td>\n",
       "        <td>6</td>\n",
       "        <td>Usher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>6</td>\n",
       "        <td>Up Up &amp; Away</td>\n",
       "        <td>5</td>\n",
       "        <td>Kid Cudi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>7</td>\n",
       "        <td>Mr. Jones</td>\n",
       "        <td>4</td>\n",
       "        <td>Counting Crows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>8</td>\n",
       "        <td>Unwell (Album Version)</td>\n",
       "        <td>4</td>\n",
       "        <td>matchbox twenty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>9</td>\n",
       "        <td>Supermassive Black Hole (Album Version)</td>\n",
       "        <td>4</td>\n",
       "        <td>Muse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>10</td>\n",
       "        <td>Fade To Black</td>\n",
       "        <td>3</td>\n",
       "        <td>Metallica</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(1, \"You're The One\", 37, 'Dwight Yoakam'),\n",
       " (2, 'Catch You Baby (Steve Pitron & Max Sanna Radio Edit)', 9, 'Lonnie Gordon'),\n",
       " (3, \"I CAN'T GET STARTED\", 9, 'Ron Carter'),\n",
       " (4, \"Nothin' On You [feat. Bruno Mars] (Album Version)\", 8, 'B.o.B'),\n",
       " (5, \"Hey Daddy (Daddy's Home)\", 6, 'Usher'),\n",
       " (6, 'Up Up & Away', 5, 'Kid Cudi'),\n",
       " (7, 'Mr. Jones', 4, 'Counting Crows'),\n",
       " (8, 'Unwell (Album Version)', 4, 'matchbox twenty'),\n",
       " (9, 'Supermassive Black Hole (Album Version)', 4, 'Muse'),\n",
       " (10, 'Fade To Black', 3, 'Metallica')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "    ROW_NUMBER()OVER(ORDER BY song_count.\"play_times\" DESC) AS \"No.\",\n",
    "    song_count.\"title\",\n",
    "    song_count.\"play_times\",\n",
    "    song_count.\"artist\"\n",
    "    FROM \n",
    "        (SELECT \n",
    "            s.\"title\",\n",
    "            count(sp.\"song_id\") AS \"play_times\",\n",
    "            a.\"name\" AS \"artist\"\n",
    "        FROM \"songs\" s\n",
    "        JOIN \"songplays\" sp ON s.\"song_id\" = sp.\"song_id\"\n",
    "        JOIN \"artists\" a ON s.\"artist_id\" = a.\"artist_id\"\n",
    "        GROUP BY s.\"title\",a.\"name\"\n",
    "        ORDER BY count(sp.\"song_id\") DESC\n",
    "        LIMIT 10\n",
    "        ) AS song_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4.4 How many songs been played for each month\n",
    "(every plays counts even it is the same song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.czwptbpzjzag.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>year</th>\n",
       "        <th>month</th>\n",
       "        <th>monthly_songs_played</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018</td>\n",
       "        <td>11</td>\n",
       "        <td>301</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(2018, 11, 301)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "    t.year,\n",
    "    t.month,\n",
    "    COUNT(sp.start_time) AS monthly_songs_played\n",
    "FROM \"songplays\" sp \n",
    "JOIN \"time\" t ON sp.start_time = t.start_time\n",
    "GROUP BY t.year, t.month\n",
    "ORDER BY t.year, t.month;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Part 5 _ Vacum/Analyze/Delete Cluster/Delete Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%sql vacuum;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%sql analyze;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.czwptbpzjzag.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      " * postgresql://dwhuser:***@dwhcluster.czwptbpzjzag.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      " * postgresql://dwhuser:***@dwhcluster.czwptbpzjzag.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      " * postgresql://dwhuser:***@dwhcluster.czwptbpzjzag.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      " * postgresql://dwhuser:***@dwhcluster.czwptbpzjzag.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      " * postgresql://dwhuser:***@dwhcluster.czwptbpzjzag.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      " * postgresql://dwhuser:***@dwhcluster.czwptbpzjzag.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql DROP TABLE IF EXISTS \"staging_events\";\n",
    "%sql DROP TABLE IF EXISTS \"staging_songs\";\n",
    "%sql DROP TABLE IF EXISTS \"songplays\";\n",
    "%sql DROP TABLE IF EXISTS \"users\";\n",
    "%sql DROP TABLE IF EXISTS \"songs\";\n",
    "%sql DROP TABLE IF EXISTS \"artists\";\n",
    "%sql DROP TABLE IF EXISTS \"time\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cluster': {'ClusterIdentifier': 'dwhcluster',\n",
       "  'NodeType': 'dc2.large',\n",
       "  'ClusterStatus': 'deleting',\n",
       "  'MasterUsername': 'dwhuser',\n",
       "  'DBName': 'dwh',\n",
       "  'Endpoint': {'Address': 'dwhcluster.czwptbpzjzag.us-west-2.redshift.amazonaws.com',\n",
       "   'Port': 5439},\n",
       "  'ClusterCreateTime': datetime.datetime(2021, 6, 9, 19, 56, 34, 807000, tzinfo=tzlocal()),\n",
       "  'AutomatedSnapshotRetentionPeriod': 1,\n",
       "  'ClusterSecurityGroups': [],\n",
       "  'VpcSecurityGroups': [{'VpcSecurityGroupId': 'sg-ab8acd9b',\n",
       "    'Status': 'active'}],\n",
       "  'ClusterParameterGroups': [{'ParameterGroupName': 'default.redshift-1.0',\n",
       "    'ParameterApplyStatus': 'in-sync'}],\n",
       "  'ClusterSubnetGroupName': 'default',\n",
       "  'VpcId': 'vpc-e7f0c69f',\n",
       "  'AvailabilityZone': 'us-west-2d',\n",
       "  'PreferredMaintenanceWindow': 'thu:12:30-thu:13:00',\n",
       "  'PendingModifiedValues': {},\n",
       "  'ClusterVersion': '1.0',\n",
       "  'AllowVersionUpgrade': True,\n",
       "  'NumberOfNodes': 4,\n",
       "  'PubliclyAccessible': True,\n",
       "  'Encrypted': False,\n",
       "  'Tags': [],\n",
       "  'EnhancedVpcRouting': False,\n",
       "  'IamRoles': [{'IamRoleArn': 'arn:aws:iam::695143239337:role/dwhRole',\n",
       "    'ApplyStatus': 'in-sync'}],\n",
       "  'MaintenanceTrackName': 'current'},\n",
       " 'ResponseMetadata': {'RequestId': 'cca9dc1a-db95-4385-ba3b-0e931cadf49e',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'cca9dc1a-db95-4385-ba3b-0e931cadf49e',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '2622',\n",
       "   'vary': 'accept-encoding',\n",
       "   'date': 'Wed, 09 Jun 2021 20:05:59 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete redshift cluster\n",
    "\n",
    "redshift.delete_cluster( ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,  SkipFinalClusterSnapshot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>dwhcluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>deleting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'dwhcluster.czwptbpzjzag.us-west-2.redshift.amazonaws.com', 'Port': 5439}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-e7f0c69f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Key  \\\n",
       "0  ClusterIdentifier   \n",
       "1  NodeType            \n",
       "2  ClusterStatus       \n",
       "3  MasterUsername      \n",
       "4  DBName              \n",
       "5  Endpoint            \n",
       "6  VpcId               \n",
       "7  NumberOfNodes       \n",
       "\n",
       "                                                                                   Value  \n",
       "0  dwhcluster                                                                             \n",
       "1  dc2.large                                                                              \n",
       "2  deleting                                                                               \n",
       "3  dwhuser                                                                                \n",
       "4  dwh                                                                                    \n",
       "5  {'Address': 'dwhcluster.czwptbpzjzag.us-west-2.redshift.amazonaws.com', 'Port': 5439}  \n",
       "6  vpc-e7f0c69f                                                                           \n",
       "7  4                                                                                      "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check status of cluster\n",
    "# deleting cluster might take several minutes, run multiple and make sure it's beed deleted\n",
    "\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# delete the IAM Role created: detach role policy, then delete role\n",
    "\n",
    "iam.detach_role_policy(RoleName=DWH_IAM_ROLE_NAME, PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\")\n",
    "iam.delete_role(RoleName=DWH_IAM_ROLE_NAME)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
